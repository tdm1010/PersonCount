{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import wget\r\n",
    "url = 'https://pjreddie.com/media/files/yolov3.weights'\r\n",
    "yolov3 = wget.download(url, out='models/yolov3.weights')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "yolov3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "from tensorflow.keras import Model\r\n",
    "from tensorflow.keras.layers import (\r\n",
    "    Add,\r\n",
    "    Concatenate,\r\n",
    "    Conv2D,\r\n",
    "    Input,\r\n",
    "    Lambda,\r\n",
    "    LeakyReLU,\r\n",
    "    UpSampling2D,\r\n",
    "    ZeroPadding2D,\r\n",
    "    BatchNormalization\r\n",
    ")\r\n",
    "from tensorflow.keras.regularizers import l2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the darknet weights and assign those weights to the layers of the model. Create a function to define the convolutional layers and whether to apply batch normalization on it or not."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wf = open('models/yolov3.weights', 'rb')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wf.seek(0)\r\n",
    "len(wf.read()) == 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_darknet_weights(model, weights_file):\r\n",
    "    '''\r\n",
    "    Helper function used to load darknet weights.\r\n",
    "    \r\n",
    "    :param model: Object of the Yolo v3 model\r\n",
    "    :param weights_file: Path to the file with Yolo V3 weights\r\n",
    "    '''\r\n",
    "    \r\n",
    "    #Open the weights file\r\n",
    "    wf = open(weights_file, 'rb')\r\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\r\n",
    "#Define names of the Yolo layers (just for a reference)    \r\n",
    "    layers = ['yolo_darknet',\r\n",
    "            'yolo_conv_0',\r\n",
    "            'yolo_output_0',\r\n",
    "            'yolo_conv_1',\r\n",
    "            'yolo_output_1',\r\n",
    "            'yolo_conv_2',\r\n",
    "            'yolo_output_2']\r\n",
    "    for layer_name in layers:\r\n",
    "        sub_model = model.get_layer(layer_name)\r\n",
    "        for i, layer in enumerate(sub_model.layers):\r\n",
    "          \r\n",
    "            \r\n",
    "            if not layer.name.startswith('conv2d'):\r\n",
    "                continue\r\n",
    "                \r\n",
    "            #Handles the special, custom Batch normalization layer\r\n",
    "            batch_norm = None\r\n",
    "            if i + 1 < len(sub_model.layers) and \\\r\n",
    "                    sub_model.layers[i + 1].name.startswith('batch_norm'):\r\n",
    "                batch_norm = sub_model.layers[i + 1]\r\n",
    "\r\n",
    "            filters = layer.filters\r\n",
    "            size = layer.kernel_size[0]\r\n",
    "            in_dim = layer.input_shape[-1]\r\n",
    "\r\n",
    "            if batch_norm is None:\r\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\r\n",
    "            else:\r\n",
    "                # darknet [beta, gamma, mean, variance]\r\n",
    "                bn_weights = np.fromfile(\r\n",
    "                    wf, dtype=np.float32, count=4 * filters)\r\n",
    "                # tf [gamma, beta, mean, variance]\r\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\r\n",
    "\r\n",
    "            # darknet shape (out_dim, in_dim, height, width)\r\n",
    "            conv_shape = (filters, in_dim, size, size)\r\n",
    "            conv_weights = np.fromfile(\r\n",
    "                wf, dtype=np.float32, count=np.product(conv_shape))\r\n",
    "            # tf shape (height, width, in_dim, out_dim)\r\n",
    "            conv_weights = conv_weights.reshape(\r\n",
    "                conv_shape).transpose([2, 3, 1, 0])\r\n",
    "\r\n",
    "            if batch_norm is None:\r\n",
    "                layer.set_weights([conv_weights, conv_bias])\r\n",
    "            else:\r\n",
    "                layer.set_weights([conv_weights])\r\n",
    "                batch_norm.set_weights(bn_weights)\r\n",
    "    \r\n",
    "    wf.seek(0)\r\n",
    "    # assert len(wf.read()) == 0, 'failed to read all data'\r\n",
    "    wf.close()\r\n",
    "    \r\n",
    "def DarknetConv(x, filters, kernel_size, strides=1, batch_norm=True):\r\n",
    "    '''\r\n",
    "    Call this function to define a single Darknet convolutional layer\r\n",
    "    \r\n",
    "    :param x: inputs\r\n",
    "    :param filters: number of filters in the convolutional layer\r\n",
    "    :param kernel_size: Size of kernel in the Conv layer\r\n",
    "    :param strides: Conv layer strides\r\n",
    "    :param batch_norm: Whether or not to use the custom batch norm layer.\r\n",
    "    '''\r\n",
    "    #Image padding\r\n",
    "    if strides == 1:\r\n",
    "        padding = 'same'\r\n",
    "    else:\r\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding\r\n",
    "        padding = 'valid'\r\n",
    "        \r\n",
    "    #Defining the Conv layer\r\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size,\r\n",
    "               strides=strides, padding=padding,\r\n",
    "               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\r\n",
    "    \r\n",
    "    if batch_norm:\r\n",
    "        x = BatchNormalization()(x)\r\n",
    "        x = LeakyReLU(alpha=0.1)(x)\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def DarknetResidual(x, filters):\r\n",
    "    '''\r\n",
    "    Call this function to define a single DarkNet Residual layer\r\n",
    "    \r\n",
    "    :param x: inputs\r\n",
    "    :param filters: number of filters in each Conv layer.\r\n",
    "    '''\r\n",
    "    prev = x\r\n",
    "    x = DarknetConv(x, filters // 2, 1)\r\n",
    "    x = DarknetConv(x, filters, 3)\r\n",
    "    x = Add()([prev, x])\r\n",
    "    return x\r\n",
    "  \r\n",
    "  \r\n",
    "def DarknetBlock(x, filters, blocks):\r\n",
    "    '''\r\n",
    "    Call this function to define a single DarkNet Block (made of multiple Residual layers)\r\n",
    "    \r\n",
    "    :param x: inputs\r\n",
    "    :param filters: number of filters in each Residual layer\r\n",
    "    :param blocks: number of Residual layers in the block\r\n",
    "    '''\r\n",
    "    x = DarknetConv(x, filters, 3, strides=2)\r\n",
    "    for _ in range(blocks):\r\n",
    "        x = DarknetResidual(x, filters)\r\n",
    "    return x\r\n",
    "def Darknet(name=None):\r\n",
    "    '''\r\n",
    "    The main function that creates the whole DarkNet.\r\n",
    "    '''\r\n",
    "    x = inputs = Input([None, None, 3])\r\n",
    "    x = DarknetConv(x, 32, 3)\r\n",
    "    x = DarknetBlock(x, 64, 1)\r\n",
    "    x = DarknetBlock(x, 128, 2)  # skip connection\r\n",
    "    x = x_36 = DarknetBlock(x, 256, 8)  # skip connection\r\n",
    "    x = x_61 = DarknetBlock(x, 512, 8)\r\n",
    "    x = DarknetBlock(x, 1024, 4)\r\n",
    "    return tf.keras.Model(inputs, (x_36, x_61, x), name=name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def draw_outputs(img, outputs, class_names):\r\n",
    "    '''\r\n",
    "    Helper, util, function that draws predictons on the image.\r\n",
    "    \r\n",
    "    :param img: Loaded image\r\n",
    "    :param outputs: YoloV3 predictions\r\n",
    "    :param class_names: list of all class names found in the dataset\r\n",
    "    '''\r\n",
    "    boxes, objectness, classes, nums = outputs\r\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\r\n",
    "    wh = np.flip(img.shape[0:2])\r\n",
    "    for i in range(nums):\r\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\r\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\r\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\r\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\r\n",
    "            class_names[int(classes[i])], objectness[i]),\r\n",
    "            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\r\n",
    "    return img\r\n",
    "\r\n",
    "yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\r\n",
    "                         (59, 119), (116, 90), (156, 198), (373, 326)],\r\n",
    "                        np.float32) / 416\r\n",
    "\r\n",
    "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])\r\n",
    "\r\n",
    "def YoloConv(filters, name=None):\r\n",
    "    '''\r\n",
    "    Call this function to define the Yolo Conv layer.\r\n",
    "    \r\n",
    "    :param flters: number of filters for the conv layer\r\n",
    "    :param name: name of the layer\r\n",
    "    '''\r\n",
    "    def yolo_conv(x_in):\r\n",
    "        if isinstance(x_in, tuple):\r\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\r\n",
    "            x, x_skip = inputs\r\n",
    "\r\n",
    "            # concat with skip connection\r\n",
    "            x = DarknetConv(x, filters, 1)\r\n",
    "            x = UpSampling2D(2)(x)\r\n",
    "            x = Concatenate()([x, x_skip])\r\n",
    "        else:\r\n",
    "            x = inputs = Input(x_in.shape[1:])\r\n",
    "\r\n",
    "        x = DarknetConv(x, filters, 1)\r\n",
    "        x = DarknetConv(x, filters * 2, 3)\r\n",
    "        x = DarknetConv(x, filters, 1)\r\n",
    "        x = DarknetConv(x, filters * 2, 3)\r\n",
    "        x = DarknetConv(x, filters, 1)\r\n",
    "        return Model(inputs, x, name=name)(x_in)\r\n",
    "    return yolo_conv\r\n",
    "\r\n",
    "def YoloOutput(filters, anchors, classes, name=None):\r\n",
    "    '''\r\n",
    "    This function defines outputs for the Yolo V3. (Creates output projections)\r\n",
    "     \r\n",
    "    :param filters: number of filters for the conv layer\r\n",
    "    :param anchors: anchors\r\n",
    "    :param classes: list of classes in a dataset\r\n",
    "    :param name: name of the layer\r\n",
    "    '''\r\n",
    "    def yolo_output(x_in):\r\n",
    "        x = inputs = Input(x_in.shape[1:])\r\n",
    "        x = DarknetConv(x, filters * 2, 3)\r\n",
    "        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\r\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],\r\n",
    "                                            anchors, classes + 5)))(x)\r\n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\r\n",
    "    return yolo_output\r\n",
    "\r\n",
    "def yolo_boxes(pred, anchors, classes):\r\n",
    "    '''\r\n",
    "    Call this function to get bounding boxes from network predictions\r\n",
    "    \r\n",
    "    :param pred: Yolo predictions\r\n",
    "    :param anchors: anchors\r\n",
    "    :param classes: List of classes from the dataset\r\n",
    "    '''\r\n",
    "    \r\n",
    "    # pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))\r\n",
    "    grid_size = tf.shape(pred)[1]\r\n",
    "    #Extract box coortinates from prediction vectors\r\n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(\r\n",
    "        pred, (2, 2, 1, classes), axis=-1)\r\n",
    "\r\n",
    "    #Normalize coortinates\r\n",
    "    box_xy = tf.sigmoid(box_xy)\r\n",
    "    objectness = tf.sigmoid(objectness)\r\n",
    "    class_probs = tf.sigmoid(class_probs)\r\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss\r\n",
    "\r\n",
    "    # !!! grid[x][y] == (y, x)\r\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\r\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\r\n",
    "\r\n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / \\\r\n",
    "        tf.cast(grid_size, tf.float32)\r\n",
    "    box_wh = tf.exp(box_wh) * anchors\r\n",
    "\r\n",
    "    box_x1y1 = box_xy - box_wh / 2\r\n",
    "    box_x2y2 = box_xy + box_wh / 2\r\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\r\n",
    "\r\n",
    "    return bbox, objectness, class_probs, pred_box\r\n",
    "\r\n",
    "def yolo_nms(outputs, anchors, masks, classes):\r\n",
    "    # boxes, conf, type\r\n",
    "    b, c, t = [], [], []\r\n",
    "\r\n",
    "    for o in outputs:\r\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\r\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\r\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\r\n",
    "\r\n",
    "    bbox = tf.concat(b, axis=1)\r\n",
    "    confidence = tf.concat(c, axis=1)\r\n",
    "    class_probs = tf.concat(t, axis=1)\r\n",
    "\r\n",
    "    scores = confidence * class_probs\r\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\r\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\r\n",
    "        scores=tf.reshape(\r\n",
    "        scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\r\n",
    "        max_output_size_per_class=100,\r\n",
    "        max_total_size=100,\r\n",
    "        iou_threshold=0.5,\r\n",
    "        score_threshold=0.6\r\n",
    "    )\r\n",
    "\r\n",
    "    return boxes, scores, classes, valid_detections\r\n",
    "\r\n",
    "\r\n",
    "def YoloV3(size=None, channels=3, anchors=yolo_anchors,\r\n",
    "           masks=yolo_anchor_masks, classes=80):\r\n",
    "  \r\n",
    "    x = inputs = Input([size, size, channels], name='input')\r\n",
    "\r\n",
    "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\r\n",
    "\r\n",
    "    x = YoloConv(512, name='yolo_conv_0')(x)\r\n",
    "    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\r\n",
    "\r\n",
    "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\r\n",
    "    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\r\n",
    "\r\n",
    "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\r\n",
    "    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\r\n",
    "\r\n",
    "    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\r\n",
    "                     name='yolo_boxes_0')(output_0)\r\n",
    "    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\r\n",
    "                     name='yolo_boxes_1')(output_1)\r\n",
    "    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\r\n",
    "                     name='yolo_boxes_2')(output_2)\r\n",
    "\r\n",
    "    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\r\n",
    "                     name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\r\n",
    "\r\n",
    "    return Model(inputs, outputs, name='yolov3')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "clear = lambda: os.system('cls') #on Windows System"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "yolo = YoloV3()\r\n",
    "load_darknet_weights(yolo, 'models/yolov3.weights') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cap = cv2.VideoCapture(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count2 = 0\r\n",
    "while(True):\r\n",
    "    count2 +=1\r\n",
    "    ret, image = cap.read()\r\n",
    "    if ret == False:\r\n",
    "        break\r\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\r\n",
    "    img = cv2.resize(img, (320, 320))\r\n",
    "    img = img.astype(np.float32)\r\n",
    "    img = np.expand_dims(img, 0)\r\n",
    "    img = img / 255\r\n",
    "    class_names = [c.strip() for c in open(\"models/classes.txt\").readlines()]\r\n",
    "    boxes, scores, classes, nums = yolo(img)\r\n",
    "    count=0\r\n",
    "    for i in range(nums[0]):\r\n",
    "        if int(classes[0][i] == 0):\r\n",
    "            count +=1\r\n",
    "\r\n",
    "    print(count2)\r\n",
    "    # print('Number of people:', count)\r\n",
    "        \r\n",
    "    image = draw_outputs(image, (boxes, scores, classes, nums), class_names)\r\n",
    "    cv2.imshow('Prediction', image)\r\n",
    "\r\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\r\n",
    "        break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "\r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nums"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}